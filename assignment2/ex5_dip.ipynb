{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "deFkWy9l-glo"
   },
   "source": [
    "# Assignment 5: Deep Image Prior\n",
    "\n",
    "**Due Date:** Feb 10, 2019.\n",
    "\n",
    "**Submission:** In pairs, [here]()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c07hXzp1p4JA"
   },
   "source": [
    "**Student 1**\n",
    "</br>**Name:** Jane Doe\n",
    "</br>**Email:** jane@doe.com\n",
    "\n",
    "\n",
    "**Student 2**\n",
    "</br>**Name:** John Doe\n",
    "</br>**Email:** john@doe.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksijbz93rB5R"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In a recent CVPR paper [Deep Image Prior](http://openaccess.thecvf.com/content_cvpr_2018/papers/Ulyanov_Deep_Image_Prior_CVPR_2018_paper.pdf) it was shown by Ulyanov et al. that deep neural nets have an inductive bias toward _natural images_: that is, if using a deep net architecture to generate an image it is _easier_ for the net to produce naturally looking images rather than noisy or blurry ones. Based on this observation, they proposed to use deep neural nets as a prior for image enhancement tasks.\n",
    "\n",
    "In this exercise we will follow their lead and try different deep architectures as _prior_ for the task of image denoising. In order to denoise an image using the _Deep Image Prior_ framework one needs a deep net that **takes random noise** and **generates the noisy image** from it (we assume we do not have the clean image, we will use it only for measuring performance). Because of the inductive bias of deep nets toward natural images we expect a clean version of the image to emerge earlier in the process before the net overfits and produces the noise as well.\n",
    "\n",
    "The exercise has three parts, with three main basic architectures:\n",
    "* 1D-Generator (generating from 1D noise)\n",
    "* 2D-Generator (generating from 2D noise)\n",
    "* 2D-Generator with skip-connections\n",
    "\n",
    "Throughout the exercise we encourage you to try various design choices so you can get the \"feel\" of working and experimenting with deep learning. We don't aim here for a specific solution, but rather are interested in the process (but we do hope you get appealing results in the end!). You are given a set of qestions for each part, please answer them but also feel free to discuss other insights you have from your experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohOOwMjR-lvO"
   },
   "source": [
    "## Setup\n",
    "FIrst, we'd like to use the free GPU provided by Google Colab. This will accelerate the training by an order of magnitude.\n",
    "1. In the menu, select: **Runtime -> Change runtime type**.\n",
    "2. Choose \"GPU\" under **Hardware accelerator**.\n",
    "\n",
    "Next, we'll need to install some python dependencies, and to download the dataset. You may need to repeat this process when the runtime is started.\n",
    "1. Run the cell **Install requirements**.\n",
    "2. Run the second cell in **Download dataset**.\n",
    "3. Restart the runtime, either by typing **\"`Ctrl+M .`\"**, or by using the menus: **Runtime -> Restrart runtime...** .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "PVDTbuNZ-l9C",
    "outputId": "c1d57e91-87f1-46f8-c556-4047ec03e1c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K    0% |▏                               | 10kB 15.4MB/s eta 0:00:01\r",
      "\u001b[K    1% |▎                               | 20kB 1.9MB/s eta 0:00:02\r",
      "\u001b[K    1% |▌                               | 30kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K    2% |▋                               | 40kB 1.8MB/s eta 0:00:02\r",
      "\u001b[K    2% |▉                               | 51kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K    3% |█                               | 61kB 2.6MB/s eta 0:00:01\r",
      "\u001b[K    3% |█▏                              | 71kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K    4% |█▎                              | 81kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K    4% |█▌                              | 92kB 3.8MB/s eta 0:00:01\r",
      "\u001b[K    5% |█▋                              | 102kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K    5% |█▉                              | 112kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K    6% |██                              | 122kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K    6% |██▏                             | 133kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K    7% |██▎                             | 143kB 7.8MB/s eta 0:00:01\r",
      "\u001b[K    7% |██▌                             | 153kB 7.8MB/s eta 0:00:01\r",
      "\u001b[K    8% |██▋                             | 163kB 7.8MB/s eta 0:00:01\r",
      "\u001b[K    8% |██▉                             | 174kB 7.8MB/s eta 0:00:01\r",
      "\u001b[K    9% |███                             | 184kB 7.8MB/s eta 0:00:01\r",
      "\u001b[K    9% |███▏                            | 194kB 7.8MB/s eta 0:00:01\r",
      "\u001b[K    10% |███▎                            | 204kB 44.6MB/s eta 0:00:01\r",
      "\u001b[K    10% |███▌                            | 215kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K    11% |███▋                            | 225kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K    11% |███▉                            | 235kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K    12% |████                            | 245kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K    12% |████▏                           | 256kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K    13% |████▎                           | 266kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K    13% |████▌                           | 276kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K    14% |████▋                           | 286kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K    14% |████▉                           | 296kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K    15% |█████                           | 307kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K    16% |█████▏                          | 317kB 41.8MB/s eta 0:00:01\r",
      "\u001b[K    16% |█████▎                          | 327kB 41.2MB/s eta 0:00:01\r",
      "\u001b[K    17% |█████▌                          | 337kB 43.4MB/s eta 0:00:01\r",
      "\u001b[K    17% |█████▋                          | 348kB 41.0MB/s eta 0:00:01\r",
      "\u001b[K    18% |█████▉                          | 358kB 41.3MB/s eta 0:00:01\r",
      "\u001b[K    18% |██████                          | 368kB 45.1MB/s eta 0:00:01\r",
      "\u001b[K    19% |██████▏                         | 378kB 45.7MB/s eta 0:00:01\r",
      "\u001b[K    19% |██████▎                         | 389kB 46.8MB/s eta 0:00:01\r",
      "\u001b[K    20% |██████▌                         | 399kB 10.1MB/s eta 0:00:01\r",
      "\u001b[K    20% |██████▋                         | 409kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K    21% |██████▉                         | 419kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K    21% |███████                         | 430kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K    22% |███████                         | 440kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K    22% |███████▎                        | 450kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K    23% |███████▍                        | 460kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K    23% |███████▋                        | 471kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K    24% |███████▊                        | 481kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K    24% |████████                        | 491kB 9.9MB/s eta 0:00:01\r",
      "\u001b[K    25% |████████                        | 501kB 44.7MB/s eta 0:00:01\r",
      "\u001b[K    25% |████████▎                       | 512kB 44.5MB/s eta 0:00:01\r",
      "\u001b[K    26% |████████▍                       | 522kB 45.9MB/s eta 0:00:01\r",
      "\u001b[K    26% |████████▋                       | 532kB 47.8MB/s eta 0:00:01\r",
      "\u001b[K    27% |████████▊                       | 542kB 47.8MB/s eta 0:00:01\r",
      "\u001b[K    27% |█████████                       | 552kB 50.9MB/s eta 0:00:01\r",
      "\u001b[K    28% |█████████                       | 563kB 51.2MB/s eta 0:00:01\r",
      "\u001b[K    28% |█████████▎                      | 573kB 49.6MB/s eta 0:00:01\r",
      "\u001b[K    29% |█████████▍                      | 583kB 49.6MB/s eta 0:00:01\r",
      "\u001b[K    29% |█████████▋                      | 593kB 49.8MB/s eta 0:00:01\r",
      "\u001b[K    30% |█████████▊                      | 604kB 50.6MB/s eta 0:00:01\r",
      "\u001b[K    30% |██████████                      | 614kB 53.9MB/s eta 0:00:01\r",
      "\u001b[K    31% |██████████                      | 624kB 54.1MB/s eta 0:00:01\r",
      "\u001b[K    32% |██████████▎                     | 634kB 53.3MB/s eta 0:00:01\r",
      "\u001b[K    32% |██████████▍                     | 645kB 51.8MB/s eta 0:00:01\r",
      "\u001b[K    33% |██████████▋                     | 655kB 49.2MB/s eta 0:00:01\r",
      "\u001b[K    33% |██████████▊                     | 665kB 41.2MB/s eta 0:00:01\r",
      "\u001b[K    34% |███████████                     | 675kB 12.1MB/s eta 0:00:01\r",
      "\u001b[K    34% |███████████                     | 686kB 11.9MB/s eta 0:00:01\r",
      "\u001b[K    35% |███████████▎                    | 696kB 11.9MB/s eta 0:00:01\r",
      "\u001b[K    35% |███████████▍                    | 706kB 11.9MB/s eta 0:00:01\r",
      "\u001b[K    36% |███████████▋                    | 716kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K    36% |███████████▊                    | 727kB 11.7MB/s eta 0:00:01\r",
      "\u001b[K    37% |████████████                    | 737kB 11.7MB/s eta 0:00:01\r",
      "\u001b[K    37% |████████████                    | 747kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K    38% |████████████▎                   | 757kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K    38% |████████████▍                   | 768kB 12.6MB/s eta 0:00:01\r",
      "\u001b[K    39% |████████████▋                   | 778kB 47.5MB/s eta 0:00:01\r",
      "\u001b[K    39% |████████████▊                   | 788kB 49.7MB/s eta 0:00:01\r",
      "\u001b[K    40% |█████████████                   | 798kB 50.2MB/s eta 0:00:01\r",
      "\u001b[K    40% |█████████████                   | 808kB 50.4MB/s eta 0:00:01\r",
      "\u001b[K    41% |█████████████▎                  | 819kB 53.5MB/s eta 0:00:01\r",
      "\u001b[K    41% |█████████████▍                  | 829kB 54.0MB/s eta 0:00:01\r",
      "\u001b[K    42% |█████████████▋                  | 839kB 52.9MB/s eta 0:00:01\r",
      "\u001b[K    42% |█████████████▊                  | 849kB 52.7MB/s eta 0:00:01\r",
      "\u001b[K    43% |█████████████▉                  | 860kB 48.6MB/s eta 0:00:01\r",
      "\u001b[K    43% |██████████████                  | 870kB 48.3MB/s eta 0:00:01\r",
      "\u001b[K    44% |██████████████▏                 | 880kB 50.3MB/s eta 0:00:01\r",
      "\u001b[K    44% |██████████████▍                 | 890kB 50.7MB/s eta 0:00:01\r",
      "\u001b[K    45% |██████████████▌                 | 901kB 50.1MB/s eta 0:00:01\r",
      "\u001b[K    45% |██████████████▊                 | 911kB 49.7MB/s eta 0:00:01\r",
      "\u001b[K    46% |██████████████▉                 | 921kB 10.9MB/s eta 0:00:01\r",
      "\u001b[K    47% |███████████████                 | 931kB 10.7MB/s eta 0:00:01\r",
      "\u001b[K    47% |███████████████▏                | 942kB 10.7MB/s eta 0:00:01\r",
      "\u001b[K    48% |███████████████▍                | 952kB 10.5MB/s eta 0:00:01\r",
      "\u001b[K    48% |███████████████▌                | 962kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K    49% |███████████████▊                | 972kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K    49% |███████████████▉                | 983kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K    50% |████████████████                | 993kB 10.6MB/s eta 0:00:01\r",
      "\u001b[K    50% |████████████████▏               | 1.0MB 10.5MB/s eta 0:00:01\r",
      "\u001b[K    51% |████████████████▍               | 1.0MB 10.5MB/s eta 0:00:01\r",
      "\u001b[K    51% |████████████████▌               | 1.0MB 43.6MB/s eta 0:00:01\r",
      "\u001b[K    52% |████████████████▊               | 1.0MB 46.9MB/s eta 0:00:01\r",
      "\u001b[K    52% |████████████████▉               | 1.0MB 48.5MB/s eta 0:00:01\r",
      "\u001b[K    53% |█████████████████               | 1.1MB 51.3MB/s eta 0:00:01\r",
      "\u001b[K    53% |█████████████████▏              | 1.1MB 51.4MB/s eta 0:00:01\r",
      "\u001b[K    54% |█████████████████▍              | 1.1MB 51.2MB/s eta 0:00:01\r",
      "\u001b[K    54% |█████████████████▌              | 1.1MB 52.0MB/s eta 0:00:01\r",
      "\u001b[K    55% |█████████████████▊              | 1.1MB 44.4MB/s eta 0:00:01\r",
      "\u001b[K    55% |█████████████████▉              | 1.1MB 45.6MB/s eta 0:00:01\r",
      "\u001b[K    56% |██████████████████              | 1.1MB 45.5MB/s eta 0:00:01\r",
      "\u001b[K    56% |██████████████████▏             | 1.1MB 45.1MB/s eta 0:00:01\r",
      "\u001b[K    57% |██████████████████▍             | 1.1MB 44.4MB/s eta 0:00:01\r",
      "\u001b[K    57% |██████████████████▌             | 1.1MB 43.9MB/s eta 0:00:01\r",
      "\u001b[K    58% |██████████████████▊             | 1.2MB 43.6MB/s eta 0:00:01\r",
      "\u001b[K    58% |██████████████████▉             | 1.2MB 44.3MB/s eta 0:00:01\r",
      "\u001b[K    59% |███████████████████             | 1.2MB 45.3MB/s eta 0:00:01\r",
      "\u001b[K    59% |███████████████████▏            | 1.2MB 44.4MB/s eta 0:00:01\r",
      "\u001b[K    60% |███████████████████▍            | 1.2MB 52.2MB/s eta 0:00:01\r",
      "\u001b[K    60% |███████████████████▌            | 1.2MB 51.8MB/s eta 0:00:01\r",
      "\u001b[K    61% |███████████████████▊            | 1.2MB 48.4MB/s eta 0:00:01\r",
      "\u001b[K    61% |███████████████████▉            | 1.2MB 47.5MB/s eta 0:00:01\r",
      "\u001b[K    62% |████████████████████            | 1.2MB 48.1MB/s eta 0:00:01\r",
      "\u001b[K    63% |████████████████████▏           | 1.2MB 48.4MB/s eta 0:00:01\r",
      "\u001b[K    63% |████████████████████▍           | 1.3MB 49.5MB/s eta 0:00:01\r",
      "\u001b[K    64% |████████████████████▌           | 1.3MB 48.2MB/s eta 0:00:01\r",
      "\u001b[K    64% |████████████████████▋           | 1.3MB 46.3MB/s eta 0:00:01\r",
      "\u001b[K    65% |████████████████████▉           | 1.3MB 47.5MB/s eta 0:00:01\r",
      "\u001b[K    65% |█████████████████████           | 1.3MB 45.6MB/s eta 0:00:01\r",
      "\u001b[K    66% |█████████████████████▏          | 1.3MB 45.8MB/s eta 0:00:01\r",
      "\u001b[K    66% |█████████████████████▎          | 1.3MB 49.0MB/s eta 0:00:01\r",
      "\u001b[K    67% |█████████████████████▌          | 1.3MB 49.6MB/s eta 0:00:01\r",
      "\u001b[K    67% |█████████████████████▋          | 1.3MB 50.3MB/s eta 0:00:01\r",
      "\u001b[K    68% |█████████████████████▉          | 1.4MB 50.5MB/s eta 0:00:01\r",
      "\u001b[K    68% |██████████████████████          | 1.4MB 48.5MB/s eta 0:00:01\r",
      "\u001b[K    69% |██████████████████████▏         | 1.4MB 50.0MB/s eta 0:00:01\r",
      "\u001b[K    69% |██████████████████████▎         | 1.4MB 50.1MB/s eta 0:00:01\r",
      "\u001b[K    70% |██████████████████████▌         | 1.4MB 50.1MB/s eta 0:00:01\r",
      "\u001b[K    70% |██████████████████████▋         | 1.4MB 33.8MB/s eta 0:00:01\r",
      "\u001b[K    71% |██████████████████████▉         | 1.4MB 33.3MB/s eta 0:00:01\r",
      "\u001b[K    71% |███████████████████████         | 1.4MB 32.5MB/s eta 0:00:01\r",
      "\u001b[K    72% |███████████████████████▏        | 1.4MB 32.1MB/s eta 0:00:01\r",
      "\u001b[K    72% |███████████████████████▎        | 1.4MB 29.2MB/s eta 0:00:01\r",
      "\u001b[K    73% |███████████████████████▌        | 1.5MB 29.0MB/s eta 0:00:01\r",
      "\u001b[K    73% |███████████████████████▋        | 1.5MB 29.3MB/s eta 0:00:01\r",
      "\u001b[K    74% |███████████████████████▉        | 1.5MB 29.1MB/s eta 0:00:01\r",
      "\u001b[K    74% |████████████████████████        | 1.5MB 29.6MB/s eta 0:00:01\r",
      "\u001b[K    75% |████████████████████████▏       | 1.5MB 29.2MB/s eta 0:00:01\r",
      "\u001b[K    75% |████████████████████████▎       | 1.5MB 42.4MB/s eta 0:00:01\r",
      "\u001b[K    76% |████████████████████████▌       | 1.5MB 42.9MB/s eta 0:00:01\r",
      "\u001b[K    76% |████████████████████████▋       | 1.5MB 43.8MB/s eta 0:00:01\r",
      "\u001b[K    77% |████████████████████████▉       | 1.5MB 45.4MB/s eta 0:00:01\r",
      "\u001b[K    78% |█████████████████████████       | 1.5MB 52.2MB/s eta 0:00:01\r",
      "\u001b[K    78% |█████████████████████████▏      | 1.6MB 51.8MB/s eta 0:00:01\r",
      "\u001b[K    79% |█████████████████████████▎      | 1.6MB 52.6MB/s eta 0:00:01\r",
      "\u001b[K    79% |█████████████████████████▌      | 1.6MB 53.3MB/s eta 0:00:01\r",
      "\u001b[K    80% |█████████████████████████▋      | 1.6MB 44.6MB/s eta 0:00:01\r",
      "\u001b[K    80% |█████████████████████████▉      | 1.6MB 45.2MB/s eta 0:00:01\r",
      "\u001b[K    81% |██████████████████████████      | 1.6MB 44.9MB/s eta 0:00:01\r",
      "\u001b[K    81% |██████████████████████████▏     | 1.6MB 45.6MB/s eta 0:00:01\r",
      "\u001b[K    82% |██████████████████████████▎     | 1.6MB 45.8MB/s eta 0:00:01\r",
      "\u001b[K    82% |██████████████████████████▌     | 1.6MB 45.0MB/s eta 0:00:01\r",
      "\u001b[K    83% |██████████████████████████▋     | 1.6MB 40.2MB/s eta 0:00:01\r",
      "\u001b[K    83% |██████████████████████████▉     | 1.7MB 36.5MB/s eta 0:00:01\r",
      "\u001b[K    84% |███████████████████████████     | 1.7MB 35.9MB/s eta 0:00:01\r",
      "\u001b[K    84% |███████████████████████████▏    | 1.7MB 33.0MB/s eta 0:00:01\r",
      "\u001b[K    85% |███████████████████████████▎    | 1.7MB 34.6MB/s eta 0:00:01\r",
      "\u001b[K    85% |███████████████████████████▍    | 1.7MB 31.8MB/s eta 0:00:01\r",
      "\u001b[K    86% |███████████████████████████▋    | 1.7MB 31.2MB/s eta 0:00:01\r",
      "\u001b[K    86% |███████████████████████████▊    | 1.7MB 28.7MB/s eta 0:00:01\r",
      "\u001b[K    87% |████████████████████████████    | 1.7MB 26.9MB/s eta 0:00:01\r",
      "\u001b[K    87% |████████████████████████████    | 1.7MB 25.5MB/s eta 0:00:01\r",
      "\u001b[K    88% |████████████████████████████▎   | 1.8MB 25.8MB/s eta 0:00:01\r",
      "\u001b[K    88% |████████████████████████████▍   | 1.8MB 27.3MB/s eta 0:00:01\r",
      "\u001b[K    89% |████████████████████████████▋   | 1.8MB 25.9MB/s eta 0:00:01\r",
      "\u001b[K    89% |████████████████████████████▊   | 1.8MB 26.4MB/s eta 0:00:01\r",
      "\u001b[K    90% |█████████████████████████████   | 1.8MB 27.8MB/s eta 0:00:01\r",
      "\u001b[K    90% |█████████████████████████████   | 1.8MB 29.6MB/s eta 0:00:01\r",
      "\u001b[K    91% |█████████████████████████████▎  | 1.8MB 29.6MB/s eta 0:00:01\r",
      "\u001b[K    91% |█████████████████████████████▍  | 1.8MB 31.0MB/s eta 0:00:01\r",
      "\u001b[K    92% |█████████████████████████████▋  | 1.8MB 32.7MB/s eta 0:00:01\r",
      "\u001b[K    92% |█████████████████████████████▊  | 1.8MB 34.3MB/s eta 0:00:01\r",
      "\u001b[K    93% |██████████████████████████████  | 1.9MB 35.6MB/s eta 0:00:01\r",
      "\u001b[K    94% |██████████████████████████████  | 1.9MB 35.9MB/s eta 0:00:01\r",
      "\u001b[K    94% |██████████████████████████████▎ | 1.9MB 37.7MB/s eta 0:00:01\r",
      "\u001b[K    95% |██████████████████████████████▍ | 1.9MB 38.7MB/s eta 0:00:01\r",
      "\u001b[K    95% |██████████████████████████████▋ | 1.9MB 37.8MB/s eta 0:00:01\r",
      "\u001b[K    96% |██████████████████████████████▊ | 1.9MB 37.2MB/s eta 0:00:01\r",
      "\u001b[K    96% |███████████████████████████████ | 1.9MB 37.3MB/s eta 0:00:01\r",
      "\u001b[K    97% |███████████████████████████████ | 1.9MB 37.4MB/s eta 0:00:01\r",
      "\u001b[K    97% |███████████████████████████████▎| 1.9MB 36.4MB/s eta 0:00:01\r",
      "\u001b[K    98% |███████████████████████████████▍| 1.9MB 36.1MB/s eta 0:00:01\r",
      "\u001b[K    98% |███████████████████████████████▋| 2.0MB 36.5MB/s eta 0:00:01\r",
      "\u001b[K    99% |███████████████████████████████▊| 2.0MB 35.9MB/s eta 0:00:01\r",
      "\u001b[K    99% |████████████████████████████████| 2.0MB 36.1MB/s eta 0:00:01\r",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 10.7MB/s \n",
      "\u001b[?25h  Building wheel for livelossplot (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#@title Install requiremnts\n",
    "#@markdown Please run this cell to install python dependencies.\n",
    "#@markdown When finished, type **`Ctrl+M .`** to restart the runtime. Alternatively, use the menus **Runtime -> Restart Runtime...**\n",
    "#@markdown This should fix the following error:<br/>`AttributeError: module 'PIL.Image' has no attribute 'register_extensions'`\n",
    "\n",
    "# Install pytorch=1.0.0\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "if accelerator.startswith('cu9'):\n",
    "  accelerator = 'cu90'  \n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
    "\n",
    "\n",
    "# Install pillow=5.4.1\n",
    "!pip install -U -q \"pillow~=5.4.1\"\n",
    "\n",
    "\n",
    "# Install livelossplot\n",
    "!pip install -U -q \"livelossplot~=0.3.0\"\n",
    "\n",
    "\n",
    "# should fix a problem with pillow\n",
    "%reload_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "4yZkfONY_NkZ"
   },
   "outputs": [],
   "source": [
    "#@title Download dataset\n",
    "#@markdown Please run this cell to download the datasets.\n",
    "\n",
    "# download images\n",
    "!wget -q https://wis-intro-vision-2019.wikidot.com/local--files/assignments/ex5-data.tar.gz\n",
    "!tar -zxf ex5-data.tar.gz && rm -f ex5-data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "3ysiWl9crAr_"
   },
   "outputs": [],
   "source": [
    "#@title Download dataset-v2\n",
    "#@markdown Please run this cell to download the datasets.\n",
    "\n",
    "# download images\n",
    "!wget -q https://wis-intro-vision-2019.wikidot.com/local--files/assignments/ex5-data-v2.tar.gz\n",
    "!tar -zxf ex5-data-v2.tar.gz && rm -f ex5-data-v2.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFD0IhE4GekW"
   },
   "source": [
    "## General imports\n",
    "\n",
    "If you encounter an error in this step, please follow the setup instructions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moTS6mxhi_L1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWwF1xDR-mWP"
   },
   "source": [
    "## Utility Methods\n",
    "\n",
    "You may want to use the provided utility functions, instead of implementing them yourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0NCIor3Cx57"
   },
   "source": [
    "### I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1MCudQ2Gix4"
   },
   "outputs": [],
   "source": [
    "def gdrive_mount():\n",
    "  if os.path.isdir('/gdrive'):\n",
    "    return True\n",
    "\n",
    "  import google.colab\n",
    "  google.colab.drive.mount('/gdrive')  \n",
    "\n",
    "\n",
    "def gdrive_path(path):\n",
    "  return os.path.join('/gdrive/My Drive', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oqNbZjT1AK4t"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "import PIL\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "# Low-Level Utility Methods\n",
    "\n",
    "def _img_to_float32(image, bounds=(0, 1)):\n",
    "  \"\"\"Receives an `image` and range `bounds`, \n",
    "     normalizes it and converts it to `float32`. \n",
    "\n",
    "  Arguments:\n",
    "    image (np.ndarray): the image\n",
    "    bounds (Tuple[float, float], optional): expected minimum and maximum values \n",
    "                                            of image pixels\n",
    "\n",
    "  Returns:\n",
    "    np.ndarray: the converted image, with `dtype=np.float32`.\n",
    "\n",
    "  \"\"\"\n",
    "  minval, maxval = bounds\n",
    "  image = np.asarray(image, dtype=np.float32) / 255.0\n",
    "  image = np.clip((maxval - minval) * image + minval, minval, maxval)\n",
    "  return image\n",
    "\n",
    "\n",
    "def _img_to_uint8(image, bounds=(0, 1)):\n",
    "  \"\"\"Receives an `image` and range `bounds`, \n",
    "     noramlizes it and converts it to `uint8`.\n",
    "\n",
    "  Arguments:\n",
    "    image (np.ndarray): the image\n",
    "    bounds (Tuple[float, float], optional): expected minimum and maximum values \n",
    "                                            of image pixels\n",
    "\n",
    "  Returns:\n",
    "    np.ndarray: the converted image, with `dtype=np.uint8`.\n",
    "    \n",
    "  \"\"\"\n",
    "  if image.dtype != np.uint8:\n",
    "    minval, maxval = bounds\n",
    "    image = (image.astype(np.float32) - minval) / (maxval - minval)\n",
    "    image = (image * 255.0).round().clip(0, 255).astype(np.uint8)\n",
    "  return image\n",
    "\n",
    "\n",
    "def _check_path(path):\n",
    "  \"\"\"Checks whether a path exists. \n",
    "  If not, the required missing directories are created\"\"\"\n",
    "  path = os.path.abspath(path)\n",
    "  if not os.path.exists(os.path.dirname(path)):\n",
    "    os.makedirs(os.path.dirname(path))\n",
    "  return path\n",
    "\n",
    "\n",
    "# High-Level Utility Methods\n",
    "\n",
    "def imread(path, size=(256, 256), bounds=(0, 1)):\n",
    "  \"\"\"Reads an image, changes its size to match `size` (may crop and lose data),\n",
    "     and converts it to float.\n",
    "  \n",
    "  Arguments:\n",
    "    path (str): path to image\n",
    "    size (Tuple[int, int], optional): desired image size\n",
    "    bounds (Tuple[float, float], optional): expected minimum and maximum values \n",
    "                                            of image pixels\n",
    "  \n",
    "  Returns:\n",
    "    image (np.ndarray): the image, where it values are in the given `bounds`.\n",
    "  \n",
    "  \"\"\"\n",
    "  image = PIL.Image.open(path).convert(mode='RGB')\n",
    "  if size is not None:\n",
    "    scale_factor = max([float(size[dim]) / float(image.size[dim]) for dim in range(2)])\n",
    "    new_size = [int(scale_factor * sz) for sz in image.size]\n",
    "    image = image.resize(new_size, PIL.Image.LANCZOS)\n",
    "    left, top = [(image.size[dim] - size[dim]) // 2 for dim in range(2)] \n",
    "    image = image.crop((left, top, left + size[0], top + size[1]))\n",
    "  image = _img_to_float32(image, bounds)\n",
    "  return image\n",
    "\n",
    "\n",
    "def imwrite(path, image, bounds=(0, 1), **kwargs):  \n",
    "  \"\"\"Normalize `image` and save it to `path`.\n",
    "\n",
    "  Arguments:\n",
    "    path (str): saving location\n",
    "    image (np.ndarray): the image\n",
    "    bounds (Tuple[float, float], optional): expected minimum and maximum values \n",
    "                                            of image pixels\n",
    "  \"\"\"  \n",
    "  image = _img_to_uint8(image, bounds)\n",
    "  path = _check_path(path)\n",
    "  image = PIL.Image.fromarray(image)\n",
    "  image.save(path, **kwargs)\n",
    "\n",
    "\n",
    "def imshow(image, path=None, **kwargs):\n",
    "  \"\"\"Normalize `image`, save it, and show it.\n",
    "\n",
    "  Arguments:\n",
    "    path (str): saving location (if None, image is save to temporary location)\n",
    "    image (np.ndarray): the image\n",
    "  \n",
    "  \"\"\"\n",
    "  fd = None\n",
    "  if path is None:\n",
    "    fd, path = tempfile.mkstemp(suffix='.png')\n",
    "  \n",
    "  imwrite(path, image, **kwargs)  \n",
    "  output = IPython.display.Image(path)\n",
    "  \n",
    "  if fd is not None:\n",
    "    os.close(fd)\n",
    "  \n",
    "  display(output)\n",
    "\n",
    "\n",
    "# colab version\n",
    "try:\n",
    "  import google.colab.widgets\n",
    "  \n",
    "  def imshow_tabs(noisy, result, clean=None, paths=None, **kwargs):\n",
    "    \"\"\"Normalizes input images (`noisy`, `result`, and possible `clean`)\n",
    "    and shows them in tabs.\n",
    "\n",
    "    Arguments:\n",
    "      noisy (np.ndarray): noisy image to show.\n",
    "      result (np.ndarray): cleaned image to show.\n",
    "      clean (np.ndarray, optional): ground truth clean image to show.\n",
    "      paths (List[str]], optional): list of locations to save the images to.\n",
    "    \n",
    "    \"\"\"\n",
    "    images = [noisy, result]\n",
    "    titles = ['noisy', 'result']\n",
    "    if clean is not None:\n",
    "      images.append(clean)\n",
    "      titles.append('clean')\n",
    "    if paths is None:\n",
    "      paths = [None] * len(titles)\n",
    "    assert len(paths) == len(titles)\n",
    "    \n",
    "    tab = google.colab.widgets.TabBar(titles)\n",
    "    \n",
    "    for title, path, image in zip(titles, paths, images):\n",
    "      with tab.output_to(title):\n",
    "        imshow(image, path=path, **kwargs)\n",
    "\n",
    "\n",
    "# jupyter version\n",
    "except ImportError:\n",
    "  import ipywidgets\n",
    "  \n",
    "  def imshow_tabs(noisy, result, clean=None, paths=None, **kwargs):\n",
    "    \"\"\"Normalizes input images (`noisy`, `result`, and possible `clean`)\n",
    "    and shows them in tabs.\n",
    "\n",
    "    Arguments:\n",
    "      noisy (np.ndarray): noisy image to show.\n",
    "      result (np.ndarray): cleaned image to show.\n",
    "      clean (np.ndarray, optional): ground truth clean image to show.\n",
    "      paths (List[str]], optional): list of locations to save the images to.\n",
    "    \n",
    "    \"\"\"\n",
    "    images = [noisy, result]\n",
    "    titles = ['noisy', 'result']\n",
    "    if clean is not None:\n",
    "      images.append(clean)\n",
    "      titles.append('clean')\n",
    "    if paths is None:\n",
    "      paths = [None] * len(titles)\n",
    "    assert len(paths) == len(titles)\n",
    "\n",
    "    tab = ipywidgets.Tab([ipywidgets.Output() for _ in titles])\n",
    "    \n",
    "    for i, (title, path, image) in enumerate(zip(titles, paths, images)):\n",
    "      tab.set_title(i, title)\n",
    "      with tab.children[i]:\n",
    "        imshow(image, path=path, **kwargs)\n",
    "    \n",
    "    display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDtR-JtbC0bT"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMllslNaCQ7c"
   },
   "outputs": [],
   "source": [
    "def root_mean_square_error(a, b):\n",
    "  \"\"\"Computes the RMSE between two images, or between two batches of images.\n",
    "  \n",
    "  Arguments:\n",
    "    a (np.ndarray): the first image (or batch of images, stacked along axis 0)\n",
    "    b (np.ndarray): the second image (or batch of images, stacked along axis 0)\n",
    "  \n",
    "  Returns:\n",
    "    rmse (float / np.ndarray): if `a` has 2 or 3 dimensions, returns the\n",
    "                               RMSE between `a` and `b`.\n",
    "                               if `a` has 4 dimensions, returns a list of\n",
    "                               RMSE between corresponding images in `a`\n",
    "                               and `b`. \n",
    "  \"\"\"\n",
    "  assert a.ndim in {2, 3, 4}, '`a` should have 2/3/4 dimensions'\n",
    "  assert a.shape == b.shape, '`a` and `b` should have the same shape'\n",
    "  \n",
    "  # batch of images\n",
    "  if a.ndim == 4:  \n",
    "    mse = np.mean((a - b)**2, axis=(1, 2, 3))\n",
    "  \n",
    "  # single image\n",
    "  else:            \n",
    "    mse = np.mean((a - b)**2)\n",
    "  \n",
    "  return np.sqrt(mse)\n",
    "    \n",
    "\n",
    "def peak_signal_noise_ratio(a, b, bounds=(0, 1)):\n",
    "  \"\"\"Computes the PSNR between two images, or between two batches of images.\n",
    "  \n",
    "  Arguments:\n",
    "    a (np.ndarray): the first image (or batch of images, stacked along axis 0)\n",
    "    b (np.ndarray): the second image (or batch of images, stacked along axis 0)\n",
    "    bounds (Tuple[float, float]): the valid bounds of `a` and `b`.\n",
    " \n",
    "  Returns:\n",
    "    psnr (float / np.ndarray): if `a` has 2 or 3 dimensions, returns the\n",
    "                               PSNR between `a` and `b`.\n",
    "                               if `a` has 4 dimensions, returns list of\n",
    "                               PSNR between corresponding images in `a`\n",
    "                               and `b`.\n",
    "  \"\"\"\n",
    "\n",
    "  assert a.ndim in {2, 3, 4}, '`a` should have 2/3/4 dimensions'\n",
    "  assert a.shape == b.shape, '`a` and `b` should have the same shape'\n",
    "  \n",
    "  minval, maxval = bounds\n",
    "  rmse = root_mean_square_error(a, b)\n",
    "  return 20 * np.log10(maxval - minval) - 20 * np.log10(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnwW0_xxCuCD"
   },
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlOLSRIhC4r-"
   },
   "outputs": [],
   "source": [
    "def list_dataset(dataset_dir='dataset'):\n",
    "  \"\"\"Lists the images in a given dataset.\n",
    "  \n",
    "  Arguments:\n",
    "    dataset_dir (str): where the dataset is.\n",
    "  \n",
    "  Returns:\n",
    "    dataset (List[str]): list of paths to images in the dataset.\n",
    "  \"\"\"\n",
    "  return sorted([os.path.join(dataset_dir, fname) for fname in os.listdir(dataset_dir)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZEZ7JDnADD5x"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXHjjeJMT4KT"
   },
   "outputs": [],
   "source": [
    "def add_noise(images, scale, bounds=(0, 1)):\n",
    "  minval, maxval = bounds\n",
    "  noise = np.random.uniform(-scale, scale, size=images.shape)\n",
    "  return np.clip(images + noise, minval, maxval)\n",
    "\n",
    "\n",
    "def add_noise_old(images, sigma, bounds=(0, 1)):\n",
    "  \"\"\"Adds i.i.d. Gaussian noise to all the pixels of an image\n",
    "  \n",
    "  Arguments:\n",
    "    images (np.ndarray): an image (or batch of images)\n",
    "    sigme (float): scale for noise\n",
    "    bounds (Tuple[float, float], optional): desired minimum and maximum values \n",
    "                                            of image pixels\n",
    "                                            \n",
    "  Returns: \n",
    "    np.ndarray: noisy images\n",
    "    \n",
    "  \"\"\"\n",
    "  minval, maxval = bounds\n",
    "  noise = np.random.normal(loc=0.0, scale=sigma, size=images.shape)\n",
    "  return np.clip(images + noise, minval, maxval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUFd7oGnQkb4"
   },
   "outputs": [],
   "source": [
    "import livelossplot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['seaborn-whitegrid', 'seaborn-notebook'])\n",
    "\n",
    "class Tracker(object):\n",
    "  def __init__(self, fig_path=None):\n",
    "    \"\"\"Creates a tracker, that keeps track of training.\n",
    "    \n",
    "    You should probably create a tracker when creating the network, because they\n",
    "    are usually coupled.\n",
    "\n",
    "    Arguments:\n",
    "      fig_path (str, optional): where to save an image of the tracker's plots.\n",
    "\n",
    "    \"\"\"\n",
    "    self._plot = livelossplot.PlotLosses(\n",
    "      plot_extrema=False,\n",
    "      fig_path=fig_path,\n",
    "      metric2title={'loss': 'Loss', 'rmse': 'RMSE', 'psnr': 'PSNR'}\n",
    "    )\n",
    "  \n",
    "  def update(self, logs):\n",
    "    \"\"\"Update the tracker's data.\n",
    "    \n",
    "    Arguments:\n",
    "      logs (dict): a dictionary with data for the tracker. Valid keys are\n",
    "                   'loss', 'rmse', 'pnsr' and 'val_*' (for the mentioned keys).\n",
    "                   'val_*' key means value on validation data.\n",
    "                   the value corresponding to the key should be a single value,\n",
    "                   not an array.\n",
    "    \n",
    "    \"\"\"\n",
    "    self._plot.update(logs)\n",
    "  \n",
    "  def draw(self):\n",
    "    \"\"\"Refresh the tracker's plot.\"\"\"\n",
    "    self._plot.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCBgX7LWSqFh"
   },
   "outputs": [],
   "source": [
    "class DeepImagePriorTrainer(object):\n",
    "  def __init__(self, noise_input, noisy_image, clean_image=None, device=None):\n",
    "    \"\"\"Trainer for Deep Image Prior, on a given pre-set example.\n",
    "    \n",
    "    Arguments:\n",
    "      noise_input (np.ndarray): vector of the noise to use as the network's input.\n",
    "      noisy_image (np.ndarray): the noisy image the network tries to learn.\n",
    "      clean_image (np.ndarray, optional): the clean image (ground truth).\n",
    "                                          SHOULD BE USED FOR VALIDATION ONLY!!!\n",
    "      device (str, optional): where to run. If None, chooses device automatically.\n",
    "                              Usually better to keep this unchanged.\n",
    "    \n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "      device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    self.device = device\n",
    "    \n",
    "    if noise_input.ndim == 3:\n",
    "      noise_input = np.transpose(noise_input, (2, 0, 1))\n",
    "    self.noise = noise_input[None, ...]\n",
    "    self.noise_t = torch.as_tensor(self.noise, dtype=torch.float32, device=self.device)\n",
    "\n",
    "    self.noisy = np.transpose(noisy_image, (2, 0, 1))[None, ...]\n",
    "    self.noisy_t = torch.as_tensor(self.noisy, dtype=torch.float32, device=self.device)\n",
    "    \n",
    "    if clean_image is not None:\n",
    "      self.clean = np.transpose(clean_image, (2, 0, 1))[None, ...]\n",
    "      self.clean_t = torch.as_tensor(self.clean, dtype=torch.float32, device=self.device)\n",
    "    else:\n",
    "      self.clean = None\n",
    "      self.clean_t = None\n",
    "\n",
    "  def train(self, net, optimizer, criterion, epochs, output_rate=50, tracker=None):\n",
    "    \"\"\"Trains a Deep Image Prior network on the pre-set example (input noise and noisy image).\n",
    "    \n",
    "    Arguments:\n",
    "      net (torch.nn.Module): your network. receives the noise, and should return the image.\n",
    "      optimizer (torch.optim.Optimizer): optimizer (make sure it's optimizing net's parameters).\n",
    "      criterion: loss function.\n",
    "      epochs (int): number of training iterations.\n",
    "      output_rate (int): how frequently (number of epochs) should the tracker's plot be refreshed.\n",
    "      tracker (Tracker, optional): tracker of the training.\n",
    "      \n",
    "    \"\"\"\n",
    "    net = net.to(self.device)\n",
    "    net.train()\n",
    "    \n",
    "    for step in range(epochs):\n",
    "      optimizer.zero_grad()\n",
    "      cleaned_t = net(self.noise_t)\n",
    "      loss_t = criterion(cleaned_t, self.noisy_t)\n",
    "      loss_t.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      logs = {}\n",
    "      cleaned = cleaned_t.cpu().detach().numpy()\n",
    "\n",
    "      # report learning on provided (noisy) image\n",
    "      loss = loss_t.item()\n",
    "      logs['rmse'] = root_mean_square_error(cleaned, self.noisy)[0]\n",
    "      logs['psnr'] = peak_signal_noise_ratio(cleaned, self.noisy)[0]\n",
    "      logs['loss'] = loss\n",
    "\n",
    "      # report learning on ground-truth (clean) image\n",
    "      if self.clean is not None:\n",
    "        with torch.no_grad():\n",
    "          val_loss_t = criterion(cleaned_t, self.clean_t)\n",
    "        val_loss = val_loss_t.item()\n",
    "        logs['val_rmse'] = root_mean_square_error(cleaned, self.clean)[0]\n",
    "        logs['val_psnr'] = peak_signal_noise_ratio(cleaned, self.clean)[0]\n",
    "        logs['val_loss'] = val_loss\n",
    "      \n",
    "      if tracker is not None:\n",
    "        tracker.update(logs)\n",
    "      \n",
    "      if step % output_rate == 0:\n",
    "        if tracker is not None:\n",
    "          tracker.draw()\n",
    "        else:\n",
    "          print(logs)  # print logs\n",
    "        \n",
    "    if tracker is not None:\n",
    "      tracker.draw()\n",
    "  \n",
    "  def eval(self, net):\n",
    "    \"\"\"Predicts the image by feeding `net` with the pre-set noise.\n",
    "    \n",
    "    Arguments:\n",
    "      net (torch.nn.Module): network to feed with input noise, and take its prediction as image.\n",
    "      \n",
    "    Returns:\n",
    "      image (np.ndarray): the predicted imaged.\n",
    "    \"\"\"\n",
    "    net = net.to(self.device)\n",
    "    net.eval()\n",
    "    \n",
    "    cleaned_t = net(self.noise_t)\n",
    "    cleaned = cleaned_t.cpu().detach().numpy()\n",
    "    return np.transpose(cleaned[0, ...], (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I9JHpe1-JHUK"
   },
   "outputs": [],
   "source": [
    "def example_main_loop(net, opt_class, opt_kwargs, criterion, noise_size, image_path, sigma, epochs, tracker=None):\n",
    "  optimizer = opt_class(net.parameters(), **opt_kwargs)\n",
    "  noise_input = np.random.normal(size=noise_size).astype(np.float32)\n",
    "  clean_image = imread(image_path, size=(256, 256))\n",
    "  noisy_image = add_noise(clean_image, sigma)\n",
    "  dip = DeepImagePriorTrainer(noise_input, noisy_image, clean_image)\n",
    "  dip.train(net, optimizer, criterion, epochs=epochs, tracker=tracker)\n",
    "  result_image = dip.eval(net)\n",
    "  imshow_tabs(noisy_image, result_image, clean_image)\n",
    "  return result_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4C8RSmN5uhDb"
   },
   "source": [
    "## Deep Image Prior\n",
    "\n",
    "In this exercise, you'll test several architectures for _Deep Image Prior_. For **each** architecture, answer the following questions (in the report):\n",
    "1. Does the \"inductive bias\" assumption hold? Do we see a clean image emerge before noise is being reconstructed? Is the net \"rich\" enough to overfit the noise?\n",
    "2. What is the effect of each design choice?\n",
    "3. Report average PSNR on all images.\n",
    "4. How many trainable parameters are in the model? How many operations (Mult/Add)?\n",
    "\n",
    "Support your claims by examples (of cleaned images), plots, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUTmxBoRid5y"
   },
   "source": [
    "### 1. 1D-Generator\n",
    "\n",
    "Construct a \"generating\" net that expects as input a 1D random noise vector, passes it through a fully connected layer to arranges it in a 2D feature space. Add \"upsampling\" convolutional layers to produce the target image.\n",
    "\n",
    "#### Design Choices\n",
    "1. \"width\" of the different layers (number of filters)\n",
    "2. Number of different layers: how many \"upsamples\", by what scale factor each time\n",
    "3. \"Upsample\" method: transposed convolution vs. interp + conv (see [here](https://distill.pub/2016/deconv-checkerboard/))\n",
    "4. How to init weights: uniform/random/zero?\n",
    "5. What loss to use? L1/L2/CE?\n",
    "6. Regularization?\n",
    "7. Solver: SGD (with and without momentum) / ADAM\n",
    "8. Learning rates: try different values `1e-5`, `1e-3`, `1e-1`, `1e1`. \\\\\n",
    "See effect of learning rate on optimization progress: slow progress vs divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y916L4EYieIe"
   },
   "outputs": [],
   "source": [
    "class Generator1D(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Generator, self).__init__()\n",
    "    \n",
    "    # ENTER YOUR SOLUTION HERE\n",
    "    raise NotImplementedError()\n",
    "   \n",
    "  def forward(self, x):\n",
    "    # ENTER YOUR SOLUTION HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAKaBYEkieVW"
   },
   "source": [
    "### 2. 2D-Generator\n",
    "\n",
    "Construct a \"U-net\": start with 2D noise the same size as the input image (but maybe more/less channels). Add some conv + stride/pooling layers to reduce spatial dimensions and creating an \"information bottleneck\", then use \"upsampling\" blocks to recover the original spatial resolution.\n",
    "\n",
    "#### Design Choices\n",
    "1. \"width\" of the different layers\n",
    "2. Number of different layers: how many \"upsamples\", by what scale factor each time\n",
    "3. \"Upsample\" method: transposed convolution vs. interp + conv (see [here](https://distill.pub/2016/deconv-checkerboard/))\n",
    "4. How to init weights: uniform/random/zero?\n",
    "5.Use the loss function that worked best for you in the previous part\n",
    "6. Regularization?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UU9PvjNie4I"
   },
   "outputs": [],
   "source": [
    "class Generator2D(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Generator, self).__init__()\n",
    "    \n",
    "    # ENTER YOUR SOLUTION HERE\n",
    "    raise NotImplementedError()\n",
    "   \n",
    "  def forward(self, x):\n",
    "    # ENTER YOUR SOLUTION HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-yuG-caimVS"
   },
   "source": [
    "### 3. 2D-Generator with skip-connections\n",
    "\n",
    "Use the same \"U-net\" architecture from previous part, but now add \"skip connections\" connecting feature maps of same spatial resolution from the \"downscale\" part to the \"upscale\" part.\n",
    "\n",
    "#### Design Choices\n",
    "1. \"width\" of the different layers, and specifically, the \"width\" of the skip connections.\n",
    "2. How to propagate the information passed through \"skip connections\": do we add it (like residual links), or concat it (like \"densenet\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83boOvbjimhK"
   },
   "outputs": [],
   "source": [
    "class Generator2DS(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Generator, self).__init__()\n",
    "    \n",
    "    # ENTER YOUR SOLUTION HERE\n",
    "    raise NotImplementedError()\n",
    "   \n",
    "  def forward(self, x):\n",
    "    # ENTER YOUR SOLUTION HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_uSuRooWvApD"
   },
   "source": [
    "## Experiments\n",
    "\n",
    "Please run your experiments below this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S43bf8G7vXpT"
   },
   "outputs": [],
   "source": [
    "dataset = list_dataset('dataset-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-R103xhrMAc"
   },
   "outputs": [],
   "source": [
    "for fp in dataset_v2:\n",
    "  im = imread(fp)\n",
    "  assert im.shape == (256, 256, 3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ex5-dip.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
